{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb231f8-2b0d-4716-82a7-a0249867c098",
   "metadata": {},
   "source": [
    "## Falcon-7b Text generation pipeline\n",
    "\n",
    "This notebook provides [falcon-7b](https://huggingface.co/tiiuae/falcon-7b-instruct) playground for text generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a455dc-e450-4c4d-93f4-40c8950fb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d73ea3-c4fe-4d95-949d-90c8cd87606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4300afc-bf34-4647-b998-b16b30bd1b14",
   "metadata": {},
   "source": [
    "#### Modify the below cell to change the GPU and/or model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a4f73-0246-4da0-89ec-f66025522542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the id of the free GPU that you are intented to use\n",
    "# Use \"auto\" instead of specifying integer id for gpu_id if unsure\n",
    "# gpu_id = \"auto\"\n",
    "gpu_id = 0\n",
    "\n",
    "model = \"tiiuae/falcon-7b-instruct\"  # \"tiiuae/falcon-7b\" is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798df42-3fd9-4765-9780-54f60a3015ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pre-trained tockeniser for the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "# Use huggingface pipeline\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=gpu_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637e7b9-364f-4e0d-b2b4-d1883a5b7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text: str) -> list[dict]:\n",
    "    \"\"\"Get response from the hugging face pipeline.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text or context (prompt) to the model\n",
    "    Returns:\n",
    "        list[dict]: Output response from the model based on teh pipeline using.\n",
    "                    Here, the key is 'generated_text' and the value is actual text generated.\n",
    "    \"\"\"\n",
    "    sequences = pipeline(\n",
    "        text,\n",
    "        max_length=200,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada6a23-5ae5-4304-8d7d-973ca4380efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(text: str) -> None:\n",
    "    \"\"\"Parse and pretty print the response generated.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text or context (prompt) to the model\n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    response = get_response(text)\n",
    "    print(f\"Prompt:\\n\\n{text}\")\n",
    "    print(\"---\" * 30)\n",
    "    print(f\"Response:\\n{response[0]['generated_text'][len(text):]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a715ac0-d794-45cf-8310-44781e496ae6",
   "metadata": {},
   "source": [
    "### Experiment by modifying the prompt in `sample_text*` and check the response\n",
    "\n",
    "Note that the current pipeline is not suitable for conversation as it doesn't have the capability to remmeber the previous queries in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705259a-9a7e-4a34-bcea-1e7a47e4ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text1 = \"\"\"Three birds on a branch, if you use a shotgun and you shoot one of the birds,\n",
    "how many birds there will be left on the branch?\"\"\"\n",
    "print_response(sample_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6611f72-7c45-4cf5-adf4-baa72160ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text2 = \"\"\"We are talking about a loud shotgun.\"\"\"\n",
    "print_response(sample_text2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
